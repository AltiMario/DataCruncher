/*
 * Copyright (c) 2019  Altimari Mario
 * All rights reserved
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package com.seer.datacruncher.scraper;

import com.gargoylesoftware.htmlunit.BrowserVersion;
import com.gargoylesoftware.htmlunit.FailingHttpStatusCodeException;
import com.gargoylesoftware.htmlunit.WebClient;
import com.gargoylesoftware.htmlunit.html.HtmlElement;
import com.gargoylesoftware.htmlunit.html.HtmlPage;
import edu.uci.ics.crawler4j.crawler.CrawlConfig;
import edu.uci.ics.crawler4j.crawler.CrawlController;
import edu.uci.ics.crawler4j.crawler.Page;
import edu.uci.ics.crawler4j.crawler.WebCrawler;
import edu.uci.ics.crawler4j.fetcher.PageFetcher;
import edu.uci.ics.crawler4j.parser.HtmlParseData;
import edu.uci.ics.crawler4j.robotstxt.RobotstxtConfig;
import edu.uci.ics.crawler4j.robotstxt.RobotstxtServer;
import edu.uci.ics.crawler4j.url.WebURL;
import org.apache.log4j.Logger;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.regex.Pattern;

public class Crawler extends WebCrawler {

    public static String url;
    private final Logger log = Logger.getLogger(this.getClass());
    private final static Pattern FILTERS = Pattern.compile(".*(\\.(css|js|bmp|gif|jpe?g"
            + "|png|tiff?|mid|mp2|mp3|mp4"
            + "|wav|avi|mov|mpeg|ram|m4v|pdf"
            + "|rm|smil|wmv|swf|wma|zip|rar|gz)(\\?.*)?)$");

    /**
     * This function specify whether the given url should be crawled or not
     */
    @Override
    public boolean shouldVisit(WebURL url) {
        String href = url.getURL().toLowerCase();
        return !FILTERS.matcher(href).matches() && href.startsWith(Crawler.url);
    }

    /**
     * This function is called when a page is fetched and ready to be processed
     */
    @Override
    public void visit(Page page) {
        String url = page.getWebURL().getURL();
        if (page.getParseData() instanceof HtmlParseData) {
            try {
                // if the page is generated by javascript like extjs 4.2
                WebClient webClient = new WebClient(BrowserVersion.FIREFOX_3_6);
                HtmlPage htmlPage = webClient.getPage(url);
                HtmlElement body = htmlPage.getBody();
                webClient.waitForBackgroundJavaScript(1000); //was 5000
                Set<String> tags = new HashSet<String>();
                Elements elements = Jsoup.parse(htmlPage.asXml()).body().getAllElements();
                for (Element e : elements) {
                    tags.add(e.tagName());

                }
                String html = htmlPage.asXml();
                for (String str : tags) {
                    for (HtmlElement elmt : body.getElementsByTagName(str)) {
                        if (elmt.hasEventHandlers("onclick")&&!elmt.hasAttribute("href")&&(!elmt.hasAttribute("unselectable")||!elmt.getAttribute("unselectable").equalsIgnoreCase("ON")) &&elmt.isDisplayed()) {
                            String s = ((HtmlPage) elmt.click()).asXml();
                            if(s.length()>html.length()){
                                html = s;
                            }
                        }
                    }
                }
                Document doc = Jsoup.parse(html);
                Elements e = doc.select("form");
                List<CrawlerHelper> listData = (List<CrawlerHelper>)myController.getCustomData();
                if (!e.isEmpty()) {
                    log.info("url=> " + url);
                    CrawlerHelper instance = new CrawlerHelper();
                    listData.add(instance);

                    for (Element et : e) {
                        instance.setName(et.attr("action"));
                        List<String> fields = new ArrayList<String>();
                        log.info("form=> " + et.attr("action"));
                        Elements ets = et.getAllElements();
                        for (Element e1 : ets) {
                            if (e1.tagName().equals("input")) {
                                if (e1.attr("type").equalsIgnoreCase("hidden") || e1.attr("type").equalsIgnoreCase("submit") ||
                                        e1.attr("type").equalsIgnoreCase("button") || e1.attr("type").equalsIgnoreCase("reset") ||
                                        e1.attr("type").equalsIgnoreCase("checkbox") || e1.attr("type").equalsIgnoreCase("radio") ){

                                    log.debug("discarded: "+e1.attr("name")); //don't need
                                } else {
                                    fields.add(e1.attr("name"));
                                    log.info(e1.attr("type") + ": " + e1.attr("name"));
                                }
                            }
                            if (e1.tagName().equals("textarea")) {
                                fields.add(e1.attr("name"));
                                log.info("A:textarea: " + e1.attr("name"));
                            }
                            if (e1.tagName().equals("select")) {
                                log.debug("discarded: "+e1.attr("name")); //don't need
                            }
                            if (e1.tagName().equals("button")) {
                                log.debug("discarded: "+e1.attr("name")); // don't need
                            }
                        }
                        instance.setFields(fields);
                    }
                }
            } catch (IOException ex) {
                log.error(ex.getMessage());
            } catch (FailingHttpStatusCodeException ex) {
                log.error(ex.getMessage());
            }
        }
    }

    public List<CrawlerHelper> getData(String webSiteURL) throws Exception {
    	
        String crawlStorageFolder = "./datacrawler";
        int numberOfCrawlers = 7;

        CrawlConfig config = new CrawlConfig();
        config.setCrawlStorageFolder(crawlStorageFolder);

        /*
         * Instantiate the controller for this crawl.
         */
        PageFetcher pageFetcher = new PageFetcher(config);
        RobotstxtConfig robotstxtConfig = new RobotstxtConfig();
        RobotstxtServer robotstxtServer = new RobotstxtServer(robotstxtConfig, pageFetcher);
        CrawlController controller = new CrawlController(config, pageFetcher, robotstxtServer);

        url = webSiteURL;
        controller.addSeed(url);

        List<CrawlerHelper> listData = new ArrayList<CrawlerHelper>();
        controller.setCustomData(listData);
        controller.start(Crawler.class, numberOfCrawlers);
     
        return listData;
    }
}
